{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "import simulation\n",
    "from heatmap import Hierarchical\n",
    "from dataloader import DataLoader\n",
    "from plotter import Plotter\n",
    "import pandas as pd\n",
    "from simulation import Simulation\n",
    "\n",
    "\n",
    "class DataTransformer:\n",
    "    def __init__(self):\n",
    "        self.data = DataLoader()\n",
    "\n",
    "        self.susc = 1.0\n",
    "        self.base_r0 = 2.2\n",
    "\n",
    "        self.upper_tri_indexes = np.triu_indices(16)\n",
    "        self.country_names = list(self.data.age_data.keys())\n",
    "\n",
    "        self.data_all_dict = dict()\n",
    "        self.data_mtx_dict = dict()\n",
    "        self.data_clustering = []\n",
    "\n",
    "        self.get_data_for_clustering()\n",
    "\n",
    "    def get_data_for_clustering(self):\n",
    "        for country in self.country_names:\n",
    "            age_vector = self.data.age_data[country][\"age\"].reshape((-1, 1))\n",
    "            contact_matrix = self.data.contact_data[country][\"home\"] + \\\n",
    "                self.data.contact_data[country][\"work\"] + \\\n",
    "                self.data.contact_data[country][\"school\"] + \\\n",
    "                self.data.contact_data[country][\"other\"]\n",
    "            contact_home = self.data.contact_data[country][\"home\"]\n",
    "            contact_school = self.data.contact_data[country][\"school\"]\n",
    "            contact_work = self.data.contact_data[country][\"work\"]\n",
    "            contact_other = self.data.contact_data[country][\"other\"]\n",
    "\n",
    "            susceptibility = np.array([1.0] * 16)\n",
    "            susceptibility[:4] = self.susc\n",
    "            simulation = Simulation(data=self.data, base_r0=self.base_r0,\n",
    "                                    contact_matrix=contact_matrix,\n",
    "                                    contact_home=contact_home,\n",
    "                                    age_vector=age_vector,\n",
    "                                    susceptibility=susceptibility)\n",
    "            self.data_all_dict.update(\n",
    "                {country: {\"beta\": simulation.beta,\n",
    "                           \"age_vector\": age_vector,\n",
    "                           \"contact_full\": contact_matrix,\n",
    "                           \"contact_home\": contact_home,\n",
    "                           \"contact_school\": contact_school,\n",
    "                           \"contact_work\": contact_work,\n",
    "                           \"contact_other\": contact_other\n",
    "                           }\n",
    "                 })\n",
    "            self.data_mtx_dict.update(\n",
    "                {country: {\"full\": simulation.beta * contact_matrix[self.upper_tri_indexes],\n",
    "                           \"home\": simulation.beta * contact_home[self.upper_tri_indexes],\n",
    "                           \"school\": simulation.beta * contact_school[self.upper_tri_indexes],\n",
    "                           \"work\": simulation.beta * contact_work[self.upper_tri_indexes],\n",
    "                           \"other\": simulation.beta * contact_other[self.upper_tri_indexes]\n",
    "                           }\n",
    "                 })\n",
    "            self.data_clustering.append(\n",
    "                simulation.beta * contact_matrix[self.upper_tri_indexes])\n",
    "        self.data_clustering = np.array(self.data_clustering)\n",
    "\n",
    "\n",
    "class Clustering:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.n_cl = 3\n",
    "\n",
    "        self.k_means_pred = None\n",
    "        self.centroids = None\n",
    "        self.closest_points = None\n",
    "        self.closest_point_idx = None\n",
    "\n",
    "    def run_clustering(self):\n",
    "        k_means = KMeans(n_clusters=self.n_cl, random_state=1)\n",
    "        k_means.fit(self.data)\n",
    "        self.k_means_pred = k_means.predict(self.data)\n",
    "        self.centroids = k_means.cluster_centers_\n",
    "\n",
    "    def get_closest_points(self):\n",
    "        self.closest_point_idx = (-1) * np.ones(self.n_cl).astype(int)\n",
    "        for c_idx, centroid in enumerate(self.centroids):\n",
    "            min_dist = None\n",
    "            for idx, point in enumerate(self.data):\n",
    "                if self.k_means_pred[idx] == c_idx:\n",
    "                    dist = np.sum((point - centroid) ** 2)\n",
    "                    if min_dist is None or dist < min_dist:\n",
    "                        min_dist = dist\n",
    "                        self.closest_point_idx[c_idx] = idx\n",
    "        self.closest_points = self.data[np.array(self.closest_point_idx).astype(int), :2]\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Create data for clustering\n",
    "    data_tr = DataTransformer()\n",
    "\n",
    "    # Reduce dimensionality\n",
    "    pca = PCA(n_components=12)\n",
    "    pca.fit(data_tr.data_clustering)\n",
    "    data_pca = pca.transform(data_tr.data_clustering)\n",
    "    print(\"Explained variance ratios:\", pca.explained_variance_ratio_,\n",
    "          \"->\", sum(pca.explained_variance_ratio_))\n",
    "\n",
    "    # Execute heatmap\n",
    "    distance = Hierarchical(data_clustering=data_tr, data_transformer=data_tr, country_names=data_tr.country_names)\n",
    "    print(\"Euclidean distance:\", pd.DataFrame.round(distance.get_euclidean_distance(), 3))\n",
    "    print(\"Manhattan distance:\", pd.DataFrame.round(distance.get_manhattan_distance(), 3))\n",
    "    distance.plot_distances()\n",
    "    # distance.heatmap_ten_countries()\n",
    "    distance.plot_ordered_distance()\n",
    "\n",
    "    # Execute clustering\n",
    "    clust = Clustering(data=data_pca)\n",
    "    clust.run_clustering()\n",
    "    clust.get_closest_points()\n",
    "\n",
    "    # Plot results for analysis\n",
    "    plotter = Plotter(clustering=clust,\n",
    "                      data_transformer=data_tr, country_names=data_tr)\n",
    "    plotter.plot_clustering()\n",
    "    centroids_orig = pca.inverse_transform(clust.centroids)\n",
    "    plotter.plot_heatmap_centroid(centroids=centroids_orig)\n",
    "    plotter.plot_heatmap_closest()\n",
    "\n",
    "    # List cluster members\n",
    "    for cluster in range(clust.n_cl):\n",
    "        print(\"Cluster\", cluster, \"(\" + plotter.colors[cluster] + \")\", \":\",\n",
    "        {data_tr.country_names[idx]: data_tr.data_all_dict[data_tr.country_names[idx]][\"beta\"]\n",
    "            for idx, x in enumerate(clust.k_means_pred) if x == cluster})\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}